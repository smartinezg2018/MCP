{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2e0319",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af2f788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# carga de datos de refencia en un data frame para su filtrado\n",
    "path = 'reference_data/'\n",
    "files = os.listdir(path)\n",
    "\n",
    "dict_files = {\n",
    "    'date':list(),\n",
    "    'link':list()\n",
    "}\n",
    "\n",
    "for file in files:\n",
    "    if '.nc' in file:\n",
    "        # generacion link\n",
    "        link = os.path.join(\n",
    "            path,\n",
    "            file\n",
    "        )\n",
    "        #Formateo fecha\n",
    "        year = file.split('_')[2]\n",
    "        month = file.split('_')[3].split('.')[0]\n",
    "        date = pd.to_datetime(year + '/' + month)\n",
    "        # Almacenamiento\n",
    "        dict_files['date'].append(date)\n",
    "        dict_files['link'].append(link)\n",
    "# Creacion del dataframe\n",
    "df_files_reference = pd.DataFrame(dict_files)\n",
    "df_files_reference.set_index(\n",
    "    'date',\n",
    "    drop=True,\n",
    "    inplace=True\n",
    ")\n",
    "df_files_reference_reference = df_files_reference.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c916422f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# carga de datos target para su filtrado\n",
    "path = 'target_data/'\n",
    "files_target = os.listdir(path)\n",
    "files_target = [path+file_name for file_name in files_target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ee385b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_by_coordenates_date_ERA(lat,long,start,end,height):\n",
    "    \"\"\"\n",
    "    se tienen los datos de reanalisis de ERA,\n",
    "    lo que se hace aquí es filtrar del data frame df_files_reference\n",
    "    la locacion, temporalidad y altura de todos los datos disponibles\n",
    "    \n",
    "    \"\"\"\n",
    "    start = str(start)\n",
    "    end = str(end)\n",
    "    height = str(height)\n",
    "\n",
    "    # se entregan los datos de fecha con el formato \"1990-01-30\"\n",
    "    mask = (df_files_reference.index>=start) & (df_files_reference.index<end)\n",
    "    df_filtered = df_files_reference[mask]\n",
    "    \n",
    "    acum = xr.open_dataset(df_filtered['link'].iloc[0]).sel(\n",
    "            latitude = lat,\n",
    "            longitude = long,\n",
    "            method = 'nearest'\n",
    "\n",
    "    )\n",
    "    for link in df_filtered[(df_filtered.index>=start) & (df_filtered.index<end)]['link'][1:].to_numpy():\n",
    "        # print(f'processing {link}')\n",
    "        temporal = xr.open_dataset(link).sel(\n",
    "            latitude= lat,\n",
    "            longitude = long,\n",
    "            method = 'nearest'\n",
    "\n",
    "        )\n",
    "        acum = xr.concat([acum,temporal],dim = \"valid_time\")\n",
    "        \n",
    "    df = acum.to_dataframe()\n",
    "    if height == '10':\n",
    "        df = np.hypot(df['u10'],df['v10'])\n",
    "    elif height == '100':\n",
    "        df = np.hypot(df['u100'],df['v100'])\n",
    "    else:\n",
    "        raise Exception('Not a valid height, type \"10\" or \"100\"')\n",
    "    \n",
    "    df.columns = ['wind_speed (m/s)']\n",
    "\n",
    "    return pd.DataFrame(df).sort_index()\n",
    "\n",
    "\n",
    "# conseguir datos de la carpeta de estaciones velocidad del viendo ideam\n",
    "def get_data_by_coordenates_date_ideam(station,start,end):\n",
    "    # se entregan los datos de fecha con el formato \"1990-01-30\"\n",
    "    \"\"\"\n",
    "    se usa el file_target como el arreglo donde están los archivos disponibles para el analisis de datos\n",
    "    se retorna un data frame de pandas con la información de velocidad de viento de ideam en la \n",
    "    estacion y años indicados\n",
    "    \"\"\"\n",
    "    start = str(start)\n",
    "    end = str(end)\n",
    "    file_path = None\n",
    "    for files_target_path in files_target:\n",
    "        if station in files_target_path:\n",
    "            file_path = files_target_path\n",
    "            break\n",
    "\n",
    "    if file_path == None:\n",
    "        raise Exception('Información de estación no disponible')\n",
    "    df = pd.read_csv(file_path,sep = '\\t')\n",
    "    df = df.set_index('fecha')\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    \n",
    "    # return df[(df.index>=start)&(df.index<end)].sort_index().resample('h').mean()\n",
    "    return df[(df.index>=start)&(df.index<end)].sort_index()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f701433",
   "metadata": {},
   "source": [
    "<h3>Desde aquí se inicia el análisis de los datos, el código anterior son funciones de apoyo</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43416a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieving reference data\n",
    "station = '0015075501'\n",
    "lat = \t12.22430556\n",
    "long = -71.98288889\n",
    "start_year = 2015\n",
    "end_year = start_year+1\n",
    "height = 10\n",
    "\n",
    "# se definen los dos puntos donde se va a realizar el MCP,\n",
    "# se define una distancia de 50 km entre ambos datos, minima distancia disponible\n",
    "df_reference = get_data_by_coordenates_date_ERA(lat, long,start_year,end_year,height)\n",
    "df_target = get_data_by_coordenates_date_ideam(station,start_year,end_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b93b953",
   "metadata": {},
   "source": [
    "Agregar la presion como posible variable, tambien temperatura , datos generales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d68aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740f6fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591e2ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(test,bins=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ede42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target = df_target.resample('d').mean()\n",
    "df_reference = df_reference.resample('d').mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0faf7b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30, 6))\n",
    "plt.plot(df_target)\n",
    "plt.plot(df_reference)\n",
    "plt.title(\"promedio diario IDEAM y ERA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e77d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30, 6))\n",
    "plt.plot(minmax_scale(df_target))\n",
    "plt.plot(minmax_scale(df_reference))\n",
    "plt.title(\"promedio diario IDEAM y ERA datos escalados minmax\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48785dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_reference,bins = 100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f09be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_target,bins = 100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20065c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# se convierten los datos en estructuras utiles para el entrenamiento de modelos\n",
    "# además de utilizar escalarlos para tener una mejor regularizacion al\n",
    "# usar Ridge y lasso\n",
    "\n",
    "x_training = minmax_scale(df_reference)\n",
    "y_training = minmax_scale(df_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a95d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, LinearRegression,LassoCV\n",
    "\n",
    "modelRidge = Ridge()\n",
    "modelRidge.fit(x_training,y_training)\n",
    "print(\"Ridge score:\",modelRidge.score(x_training,y_training))\n",
    "\n",
    "modelLinear = LinearRegression()\n",
    "modelLinear.fit(x_training,y_training)\n",
    "print(\"Linear score:\",modelLinear.score(x_training,y_training))\n",
    "\n",
    "modelLasso = LassoCV(alphas = [0.0001, 0.001,0.01, 0.1, 1, 10]).fit(x_training, y_training)\n",
    "modelLasso.fit(x_training,y_training)\n",
    "print(\"Lasso score:\",modelLasso.score(x_training,y_training))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3ce105",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_training, y_training, label=\"Data Points\")\n",
    "plt.plot(x_training,modelLinear.predict(x_training),'C1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2bd794",
   "metadata": {},
   "source": [
    "Ahora nos encontramos con una problematica planteada en el articulo Reconstructing long‑term wind speed data based on measure correlate predict method for micro‑grid planning, donde se nos dice que este acercamiento a los datos puede tener un subajuste, además de plantearse la problemática de realizar este tipo de caracterizaciones teniendo estaciones con muy baja correlación. por esto mismo vamos a realizar la implementación de el articulo previamente mencionado.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3380842a",
   "metadata": {},
   "source": [
    "<h3>Replicación paper: Reconstructing long‑term wind speed data based on measure \n",
    "correlate predict method for micro‑grid planning</h3>\n",
    "se van a usar datos del 2011 de un aeropuerto de Colombia y los de Reanalisis del ERA\n",
    "\n",
    "el plan de accion sería el siguiente:\n",
    "<ol>\n",
    "<li>se define año y coordenadas para la realización del MCP.</li>\n",
    "<li>tener un data frame de referencia que cargamos con los métodos previamente planteados, los datos serían del ERA.</li>\n",
    "<li>tener un data frame objetivo, este se crea a partir de los datos de las estaciones de IDEAM.</li>\n",
    "<li>se realizan las tranformaciones necesarias de los datos para poder realizar una correlación entre ellos,</br> además de usarse en el CRP y al momento de entrenar modelos.</li>\n",
    "<li>se realiza el metodo de CRP para confirmar la relación de los datos.</li>\n",
    "<li>se realizan ls RBFNN para lograr una caracterización de la ubicación objetivo.</li>\n",
    "<li>se realizan algoritmos geneticos para optimizar este método.</li>\n",
    "<li>se plantea la experimentacion con otras redes: LSTM, RNN y demás métodos de forecasting.</li>\n",
    "<li>se optimizan los métodos con mejores scores utilizando algoritmos genéticos y grid search.</li>\n",
    "\n",
    "<h2>Pendientes</h2>\n",
    "- revisar las correlaciones entre las variables disponibles: temperatura, presion, punto de rocio </br>\n",
    "- terminar la replicación del articulo</br>\n",
    "- revisar como implementar tsne</br>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a31a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('SKVP.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f007099",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['valid'] = pd.to_datetime(df['valid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1cae5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b084b267",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index('valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50594ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e2e40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df['sped']>=df['sped'].quantile(0.01))& (df['sped']<=df['sped'].quantile(0.99))\n",
    "df = df[mask]\n",
    "df = df['sped'].resample('h').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436f29c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd24c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(20,4))\n",
    "plt.plot(df[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cefd6f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
